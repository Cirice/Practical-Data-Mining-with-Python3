{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "Many applications require being able to decide whether a new observation belongs to the same distribution as existing observations(it is an inlier), or should be considered as different(it is an outlier). Often, this ability is used to clean real data sets. \n",
    "Two important distinction must be made:\n",
    "### Novelty detection:\n",
    " \tThe training data is not polluted by outliers, and we are interested in detecting anomalies in new observations.\n",
    "\n",
    "### Outlier detection:\n",
    "    The training data contains outliers, and we need to fit the central mode of the training data, ignoring the deviant observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# need this for using pandas built-in plotting facility\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# please visit 'http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py'\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "pandas.set_option('display.max_rows', 10)\n",
    "pandas.set_option('display.max_columns', 10)\n",
    "\n",
    "# set a fixed seed for numpy pseudo random generator\n",
    "numpy.random.seed(100)\n",
    "\n",
    "# build an mm scaler for later use\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a compressed csv file\n",
    "data = pandas.read_csv(\"./datasets/creditcardfraud.zip\", compression='zip', header=0,  sep=',')\n",
    "\n",
    "# tell me how much memory 'data' is using?\n",
    "data.memory_usage()/(2**20), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's peek into the data a always\n",
    "data\n",
    "\n",
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show me a crude descrition of the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# show me the historgram for 'Class'\n",
    "data['Class'].plot.hist()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# how many 1s do we have in 'Class'?\n",
    "data[data['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "subset_features = ['V1', 'V2', 'V3', 'V4', 'V5']\n",
    "\n",
    "scaled_subset =pandas.DataFrame(\n",
    "    scaler.fit_transform(data[subset_features]),\n",
    "    columns=subset_features)\n",
    "\n",
    "# show me the historgram for 'Class'\n",
    "scaled_subset.iloc[0:50].plot.hist(stacked=True, \n",
    "                                    bins=10, alpha=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the column names\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', \n",
    "'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15',\n",
    "'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', \n",
    "'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "\n",
    "target = ['Class']\n",
    "\n",
    "data[data['Class'] == numpy.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Class.dropna(inplace=True)\n",
    "X = data[features]\n",
    "Y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pandas.DataFrame(scaler.fit_transform(X), columns=features)\n",
    "\n",
    "# first column is not sclaed, the second one is scaled\n",
    "pandas.concat([X.loc[0:100, 'V6'],\n",
    "               X_scaled.loc[0:100, 'V6']], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an RFE object to rank each feature\n",
    "cls = GradientBoostingClassifier()\n",
    "rfe = RFE(estimator=cls, n_features_to_select=3, step=1.0)\n",
    "margin = 1000\n",
    "rfe.fit(X_scaled.iloc[0:margin], Y.iloc[0:margin])\n",
    "\n",
    "# less is better(1 is the best)\n",
    "rfe.ranking_\n",
    "#rfe.n_features_\n",
    "#rfe.estimator_\n",
    "#rfe.get_support()\n",
    "\n",
    "# make a dictionay object in sahpe of {'feature': 'rank'}\n",
    "rank = dict(zip(features, rfe.ranking_))\n",
    "rank\n",
    "\n",
    "#cls.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Amount.describe()\n",
    "data[(X.Amount > 10) & (Y.Class == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test and train data\n",
    "selected_features = ['V12', 'V23', 'Amount']\n",
    "X_train, X_test, y_train, y =\\\n",
    "train_test_split(X[selected_features], Y, test_size=0.1)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_hat = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show me the report\n",
    "print(metrics.classification_report(y_hat, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision, Recall, F Score, Support,  Accuracy (In Binary Classification)\n",
    "\n",
    "![Precion and Recall](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)\n",
    "\n",
    "![F_x Score](https://wikimedia.org/api/rest_v1/media/math/render/svg/49d1ff4917ee4c464f6efbee08735b4a8694e8c0)\n",
    "\n",
    "<!-- ![TN, TP, FP ansd FN](https://upload.wikimedia.org/wikipedia/commons/6/65/Binary-classification-labeled.svg)\n",
    "-->\n",
    "\n",
    "![Accuracy](https://wikimedia.org/api/rest_v1/media/math/render/svg/e2e427ec6dcf2d7882c3bbdc659a8204cba59dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very very suspicious!\n",
    "print(metrics.accuracy_score(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is very unbiased it seems!\n",
    "a = data[data.Class == 1].shape[0]\n",
    "b = data.shape[0]\n",
    "a/b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
